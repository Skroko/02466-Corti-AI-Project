transformer:
  encoder:
    hidden: 256
    layers: 4
    heads: 2
    activation: 'ReLU'
    dropout: 0.2
    conv_filter_size: 1024
  decoder:
    hidden: 256
    layers: 6
    heads: 2
    activation: 'ReLU'
    dropout: 0.2
    conv_filter_size: 1024

max_seq_len: 1000

variance-adaptor:
  pitch:
    n_bins: 256
    type: 'linear'
  energy:
    n_bins: 256
    type: 'linear'

variance-predictor:
  out-channels: 256
  kernel: 3
  dropout: 0.5

postnet:
  kernel_size: 5
  layers: 5
  dropout: 0.5

vocoder:
  model: "HiFi-GAN" # support 'HiFi-GAN', 'MelGAN'
  speaker: "LJSpeech" # support  'LJSpeech', 'universal'
model:
  transformer:
    encoder:
      hidden: 
        256
  
  variance-predictor:
    out-channels: 
      256
    kernel:
      3
    dropout:
      0.5
      
# Cool text that says something cool

transformer:
  d_model:
    12
  hidden_dim:
    4
  act_fnc:
    nn.ReLU
  dropout:
    0.0
  N_heads:
    2
  d_k:
    2
  d_v:
    2
  batch_size:
    3
  seq_len:
    4
  N_layers:
    2

postnet:
  kernel_size:
    3
  n_mel_channels:
    15
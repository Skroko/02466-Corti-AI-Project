model:
  transformer:
    encoder:
      hidden: 
        256
  
  variance-predictor:
    out-channels: 
      256
    kernel:
      3
    dropout:
      0.5
      
# Cool text that says something cool

transformer:
  d_model:
    2
  hidden_dim:
    2
  act_fnc:
    nn.ReLU
  dropout:
    0.0
  N_heads:
    2
  d_k:
    2
  d_v:
    2
  batch_size:
    2
  seq_len:
    2
  N_layers:
    2
